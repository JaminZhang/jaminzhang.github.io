---
layout: post
title: 负载均衡简介
description: "负载均衡简介"
category: LB
avatarimg:
tags: [LB]
duoshuo: true
---

# 引言

前面一篇文章对计算机集群概念进行了简介，其中谈到了负载均衡集群，下面我们来学习下负载均衡。  

# 简介

负载均衡（Load Balancing）是一种计算机网络技术，
用来在多个计算机（计算机集群）、网络连接、CPU、磁盘驱动器或其他资源中分配负载，
以达到最佳化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。  
使用带有负载均衡的多个服务器组件，取代单一的组件，可以通过冗余提高可靠性。  
负载均衡服务通常是由专用软体和硬件来完成。

<pre>

基于互联网的服务

负载均衡最重要的一个应用是利用多台服务器提供单一服务，这种方案有时也称之为服务器农场。  
通常，负载均衡主要应用于 Web 网站，大型的 Internet Relay Chat 网络，高流量的文件下载网站，
NNTP（Network News Transfer Protocol）服务和 DNS 服务。
现在负载均衡器也开始支持数据库服务，称之为数据库负载均衡器。

对于互联网服务，负载均衡器通常是一个软体程序，这个程序侦听一个外部端口，互联网用户可以通过这个端口来访问服务，
而作为负载均衡器的软体会将用户的请求转发给后台内网服务器，
内网服务器将请求的响应返回给负载均衡器，负载均衡器再将响应发送到用户，
这样就向互联网用户隐藏了内网结构，阻止了用户直接访问后台（内网）服务器，使得服务器更加安全，
可以阻止对核心网络栈和运行在其它端口服务的攻击。
当所有后台服务器出现故障时，有些负载均衡器会提供一些特殊的功能来处理这种情况。
例如转发请求到一个备用的负载均衡器、显示一条关于服务中断的消息等。
负载均衡器使得 IT 团队可以显著提高容错能力。它可以自动提供大量的容量以处理任何应用程序流量的增加或减少。

</pre>

# 负载均衡原理

系统的扩展可分为纵向（垂直）扩展和横向（水平）扩展。  
纵向扩展，是从单机的角度通过增加硬件处理能力，比如 CPU 处理能力，内存容量，磁盘等方面，实现服务器处理能力的提升，
不能满足大型分布式系统（网站），大流量，高并发，海量数据的问题。  
因此需要采用横向扩展的方式，通过添加机器来满足大型网站服务的处理能力。
比如：一台机器不能满足，则增加两台或者多台机器，共同承担访问压力。 

负载均衡的作用（解决的问题）：

1. 解决并发压力，提高应用处理性能（增加吞吐量，加强网络处理能力）；
2. 提供故障转移，实现高可用；
3. 通过添加或减少服务器数量，提供网站伸缩性（扩展性）；
4. 安全防护；（负载均衡设备上做一些过滤，黑白名单等处理）

# 负载均衡分类

根据实现技术不同，可分为 DNS 负载均衡，链路层负载均衡，IP 负载均衡，HTTP 负载均衡等。


## 1. DNS 负载均衡

最早的负载均衡技术，利用域名解析实现负载均衡，在 DNS 服务器，配置多个 A 记录，这些 A 记录对应的服务器构成集群。  
大型网站总是部分使用 DNS 解析，作为第一级负载均衡。  

**优点**  

* 使用简单：负载均衡工作，交给 DNS 服务器处理，省掉了负载均衡服务器维护的麻烦
* 提高性能：可以支持基于地址的域名解析，解析成距离用户最近的服务器地址，可以加快访问速度，改善性能；  

**缺点**  

* 可用性差：DNS 解析是多级解析，新增/修改 DNS 后，解析时间较长；解析过程中，用户访问网站将失败；
* 扩展性低：DNS 负载均衡的控制权在域名商那里，无法对其做更多的改善和扩展；
* 维护性差：也不能反映服务器的当前运行状态；支持的算法少；不能区分服务器的差异（不能根据系统与服务的状态来判断负载）
 
**实践建议**  

将 DNS 作为第一级负载均衡，A 记录对应着内部负载均衡的 IP 地址，通过内部负载均衡将请求分发到真实的 Web 服务器上。
一般用于互联网公司，复杂的业务系统不合适使用。  

## 2. 链路层负载均衡

在通信协议的数据链路层修改 MAC 地址，进行负载均衡。  

数据分发时，不修改 IP 地址，只修改目标 MAC 地址，配置真实物理服务器集群所有机器虚拟 IP 和负载均衡服务器 IP 地址一致，
达到不修改数据包的源地址和目标地址，进行数据分发的目的。  

实际处理服务器 IP 和数据请求目的 IP 一致，不需要经过负载均衡服务器进行地址转换，
可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。也称为直接路由模式（DR 模式）。

**优点**:性能好

**缺点**:配置复杂

**实践建议**:DR 模式是目前使用最广泛的一种负载均衡方式。  


## 3. IP 负载均衡

在网络层通过修改请求目标地址进行负载均衡。  

用户请求数据包，到达负载均衡服务器后，负载均衡服务器在操作系统内核进程获取网络数据包，
根据负载均衡算法得到一台真实服务器地址，然后将请求目的地址修改为获得的真实 IP 地址，不需要经过用户进程处理。  

真实服务器处理完成后，响应数据包回到负载均衡服务器，负载均衡服务器再将数据包源地址修改为自身的 IP 地址，发送给用户浏览器。  

IP 负载均衡中，真实物理服务器返回给负载均衡服务器，存在两种方式：

1. 负载均衡服务器在修改目的 IP 地址的同时修改源地址。将数据包源地址设为自身，即源地址转换（SNAT）。
2. 将负载均衡服务器同时作为真实物理服务器集群的网关服务器。

**优点**  
在内核进程完成数据分发，比在应用层分发性能更好

**缺点**  
所有请求响应都需要经过负载均衡服务器，集群最大吞吐量受限于负载均衡服务器网卡带宽

# 4. 混合型负载均衡

由于多个服务器群内硬件设备、各自的规模、提供的服务等的差异，可以考虑给每个服务器群采用最合适的负载均衡方式，
然后又在这多个服务器群间再一次负载均衡或群集起来以一个整体向外界提供服务（即把这多个服务器群当做一个新的服务器群），从而达到最佳的性能。
将这种方式称之为混合型负载均衡。  

此种方式有时也用于单台均衡设备的性能不能满足大量连接请求的情况下。是目前大型互联网公司，普遍使用的方式。  

# 硬件负载均衡

采用硬件的方式实现负载均衡，一般是单独的负载均衡服务器，价格昂贵，一般土豪级公司可以考虑，业界领先的有两款，F5 和 A10。  

使用硬件负载均衡，主要考虑一下几个方面：  

1. 功能考虑：功能全面支持各层级的负载均衡，支持全面的负载均衡算法，支持全局负载均衡；
2. 性能考虑：一般软件负载均衡支持到 5 万级并发已经很困难了，硬件负载均衡可以支持
3. 稳定性：商用硬件负载均衡，经过了良好的严格的测试，经过大规模使用，在稳定性方面高；
4. 安全防护：硬件均衡设备除具备负载均衡功能外，还具备防火墙，防 DDOS 攻击等安全功能；
5. 维护角度：提供良好的维护管理界面，售后服务和技术支持；
6. 土豪公司：F5 BIG-IP 价格：15w~55w 不等；A10 价格：55w-100w 不等；

**缺点**  

1. 价格昂贵；
2. 扩展能力差；


# 云计算负载均衡

适用于中小公司，相关介绍文档如下：

[阿里云负载均衡](https://www.aliyun.com/product/slb)  
[阿里云 SLB 专题页](https://promotion.aliyun.com/ntms/act/slblearn.html)  
[阿里云负载均衡文档](https://help.aliyun.com/product/27537.html)   


## 小结

1. 一般硬件的负载均衡也要做双机高可用，因此成本会比较高。
2. 互联网公司一般使用开源软件，因此大部分应用采用软件负载均衡；部分采用硬件负载均衡。


# Ref
[负载均衡 (计算机)](https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1_(%E8%AE%A1%E7%AE%97%E6%9C%BA))  
[大型网站架构系列：负载均衡详解（1）](http://www.cnblogs.com/itfly8/p/5043435.html)  
